Оценка Чернова даёт экспоненциально убывающие оценки вероятности больших отклонений сумм независимых случайных величин.
Эти оценки являются более точными, чем оценки, полученные с использованием первых или вторых моментов, такие как неравенство Маркова или неравенство Чебышёва, которые дают лишь степенной закон убывания.
Вместе с тем оценка Чернова требует, чтобы случайные величины были независимы в совокупности — условие, которое ни неравенство Маркова, ни неравенство Чебышёва не требуют, хотя неравенство Чебышёва требует попарную независимость случайных величин.
Оценка Чернова имеет отношение к неравенствам Бернштейна и неравенству Хёфдинга, которые ей исторически предшествуют.
Основной случай оценки Чернова для случайной величины 
  
    
      
        X
      
    
    
  
 достигается применением неравенства Маркова к .mw-parser-output .ts-mathetX  1 . Для каждого 
  
    
      
        t
        >
        0
      
    
    
  
 
Когда X является суммой n случайных величин X1, ... ,Xn, для любого 
  
    
      
        t
        >
        0
      
    
    
  
В частности, оптимизируя по t и предполагая, что Xi  независимы, мы получаем
Аналогично
и, таким образом,
Конкретные значения оценок Чернова получаются вычислением 
  
    
      
        
          E
        
        
          
        
      
    
     \left}
  
для конкретных величин 
  
    
      
        
          X
          
            i
          
        
      
    
    }
  
.
Пусть X1, ..., Xn — независимые случайные величины Бернулли, сумма которых X, и каждая равна 1 с вероятностью 
  
    
      
        p
        >
        0.5
      
    
    
  
. Для переменной Бернулли верно:
следовательно,
Для всякого 
  
    
      
         
        >
        0
      
    
    
  
 при 
  
    
      
        t
        =
        ln
         
        
        >
        0
      
    
    
  
 и 
  
    
      
        a
        =
        
        n
        p
      
    
    
  
 получаем
и общий случай оценки Чернова даёт 2 :64
Вероятность одновременного свершения более чем n/2 событий   в точности равна:
Нижнюю оценку этой вероятности можно вычислить с помощью неравенства Чернова: 
В самом деле, обозначая μ = np, мы получаем мультипликативную форму оценки Чернова  3 :
Этот результат допускает разнообразные обобщения, как отмечено ниже.
Можно отметить несколько форм оценок Чернова: исходную аддитивную форму  или более практичную мультипликативную форму .
Следующая Теорема была доказана Василием Хёфдингом 4 .
Более простая оценка получается ослаблением этой теоремы, используя неравенство D ≥ 2ε2, которое следует из выпуклости D и того факта, что
Этот результат является частным случаем неравенства Хёфдинга.
В некоторых случаях используются оценки
более сильные при p < 18.
Аналогичным образом можно показать, что для любого  
  
    
      
        0
        <
         
        <
        1
        ,
      
    
    
  
На практике вышеприведённая формула часто оказывается громоздкой 2 , поэтому используются более слабые, но удобные оценки 
которые получаются с помощью неравенства 
  
    
      
        
          
            
              2
               
            
            
              2
              +
               
            
          
        
         
        ln
         
        
      
    
    
  
 из списка логарифмических неравенств 5 . Или ещё более слабое неравенство 
Оценки Чернова имеют приложения в уравновешивании множеств и маршрутизации пакетов в разреженных сетях.
Проблема уравновешения множества возникает при проектировании статистического эксперимента. Как правило, при проектировании статистического эксперимента с заданными в этом эксперименте свойствами участников нам необходимо разделить участников на две непересекающиеся группы так, чтобы каждое свойство было, насколько это возможно, сбалансировано между двумя группами. См. также информацию в Probability and Computing: Randomized Algorithms and Probabilistic Analysis Архивная копия от 16 апреля 2021 на Wayback Machine. 
Оценки Чернова также используются для достижения жестких границ в задачах маршрутизации с использованием перестановок. Это уменьшает перегруженность при маршрутизации в разреженных сетях. См. подробнее в Probability and Computing: Randomized Algorithms and Probabilistic Analysis Архивная копия от 16 апреля 2021 на Wayback Machine.  
Также оценки Чернова находят применение в теории вычислительного обучения для доказательства того, что обучающий алгоритм аппроксимационно по вероятности корректен. То есть с высокой вероятностью этот алгоритм имеет малую ошибку на достаточно большом наборе тренировочных данных 6 .
Оценки Чернова могут быть эффективно использованы для оценки "уровня робастности" приложения/алгоритма посредством исследования его пространства возмущений при помощи рандомизации. 7   
Рудольф Альсведе и Андреас Винтер использовали оценки Чернова для случайных величин с матричными значениями. 8  Следующую версию неравенства можно найти в работе Троппа. 9 
Пусть M1, ..., Mt — случайные величины с матричными значениями такие, что 
  
    
      
        
          M
          
            i
          
        
         
        
          
            C
          
          
            
              d
              
                1
              
            
             
            
              d
              
                2
              
            
          
        
      
    
    \in \mathbb \times d_
  
 и 
  
    
      
        
          E
        
        
        =
        0
      
    
     =0}
  
. Обозначим 
  
    
      
         
        M
         
      
    
    
  
 оператор нормы матрицы 
  
    
      
        M
      
    
    
  
. Если неравенство 
  
    
      
         
        
          M
          
            i
          
        
         
         
         
      
    
    \rVert \leq \gamma }
  
  почти наверное выполнено для всех 
  
    
      
        i
         
        
      
    
    }
  
, то для каждого ε > 0 
Чтобы заключить, что отклонение от 0 ограничено величиной ε с высокой вероятностью, нам нужно выбрать 
  
    
      
        t
      
    
    
  
  пропорциональным логарифму 
  
    
      
        
          d
          
            1
          
        
        +
        
          d
          
            2
          
        
      
    
    +d_
  
. В общем случае зависимость от 
  
    
      
        ln
         
        
        )
      
    
    
  
 неочевидна: например, возьмём диагональную случайную матрицу знаков размерности 
  
    
      
        d
         
        d
      
    
    
  
. Оператор нормы суммы 
  
    
      
        t
      
    
    
  
  независимых образцов является в точности максимальным отклонением среди 
  
    
      
        d
      
    
    
  
 независимых случайных блужданий длины 
  
    
      
        t
      
    
    
  
.
Для того, чтобы достичь фиксированную границу максимального отклонения с постоянной вероятностью, 
  
    
      
        t
      
    
    
  
 должно логарифмически возрастать вместе с 
  
    
      
        d
      
    
    
  
. 10 
Следующая теорема получена в предположении, что 
  
    
      
        M
      
    
    
  
 имеет низкий ранг, для того, чтобы избежать зависимости от размерности. 
Пусть 0 < ε < 1 и 
  
    
      
        M
      
    
    
  
 ─ случайная симметрическая вещественная матрица с 
  
    
      
         
        
          E
        
        
         
         
        1
      
    
     \|\leq 1}
  
 и 
  
    
      
         
        M
         
         
         
      
    
    
  
 почти наверное. Предположим, что каждый элемент носителя 
  
    
      
        M
      
    
    
  
 имеет ранг самое большее 
  
    
      
        r
      
    
    
  
. Положим 
Если 
  
    
      
        r
         
        t
      
    
    
  
 почти наверное, то
где M1, ..., Mt — это независимые одинаково распределенные копии 
  
    
      
        M
      
    
    
  
.
Анкит Гарг, Инь Тат Ли, Чжао Сонг и Нихил Шривастава 11  получили оценки типа Чернова для сумм матричнозначных случайных величин, семплированных с помощью случайного блуждания экспандера.  
Расмус Кинг и Чжао Сонг 12  получили оценки типа Чернова для сумм матриц лапласианов случайных деревьев.
Следующий вариант оценки Чернова можно использовать для оценки вероятности того, что большинство популяции станет в выборке меньшинством и наоборот. 13 
Предположим, имеется общая популяция 
  
    
      
        A
      
    
    
  
 и подпопуляция 
  
    
      
        B
         
        A
      
    
    
  
. Обозначим относительный размер подпопуляции  через 
  
    
      
        r
      
    
    
  
.
Допустим, мы выбираем целое кисло 
  
    
      
        k
      
    
    
  
 и случайную выборку 
  
    
      
        S
         
        A
      
    
    
  
 размера 
  
    
      
        k
      
    
    
  
. Обозначим относительный размер подпопуляции  через 
  
    
      
        
          r
          
            S
          
        
      
    
    }
  
.
Тогда для каждой доли 
  
    
      
        d
         
        
      
    
    
  
:   
В частности, если 
  
    
      
        B
      
    
    
  
 ─ это большинство в 
  
    
      
        A
      
    
    
  
 , то мы можем оценить сверху вероятность того, что 
  
    
      
        B
      
    
    
  
 останется большинством в 
  
    
      
        S
        
        ,
      
    
    
  
 взяв 
  
    
      
        d
        =
        1
         
        
          
            1
            
              2
              r
            
          
        
      
    
    
  
 14 :
  
    
      
        P
        
          
        
        >
        1
         
        exp
         
        
          
              
              
                2
              
            
             
            k
            
              /
            
            2
          
          )
        
        .
      
    
    \cdot k/2\right).}
  
Эта оценка, разумеется, не является точной.
Например, если 
  
    
      
        r
        =
        0.5
      
    
    
  
, то мы получаем тривиальную оценку 
  
    
      
        P
        >
        0
      
    
    
  
.
Пусть q = p + ε. Взяв a = nq в формуле , получаем:
Теперь, зная что Pr = p, Pr = 1 − p, имеем
Таким образом, мы можем легко вычислить минимум, используя технику дифференцирования:
Приравнивая полученное выражение к нулю и разрешая уравнение относительно 
  
    
      
        t
      
    
    
  
, получаем
так что
Следовательно,
Поскольку q = p + ε > p, то мы видим, что  t > 0, так что наша оценка удовлетворяется по t. Получив t, мы можем вернуться в предыдущие уравнения и найти
Теперь мы имеем желаемый результат, поскольку
Для завершения доказательства в симметрическом случае мы попросту определим случайную величину Yi = 1 − Xi, применим к ней точно такое же доказательство и присоединим результат к нашей оценке.
Положим Pr = pi. Согласно формуле ,
Третья строчка следует из того, что 
  
    
      
        
          e
          
            t
            
              X
              
                i
              
            
          
        
      
    
    }}
  
 принимает значение et с вероятностью pi и значение 1 с вероятностью 1 − pi. Это идентично вычислениям выше в доказательстве аддитивной формы.
Переписав 
  
    
      
        
          p
          
            i
          
        
        
          e
          
            t
          
        
        +
        
      
    
    e^
  
 как 
  
    
      
        
          p
          
            i
          
        
        
        +
        1
      
    
    +1}
  
 и вспомнив, что 
  
    
      
        1
        +
        x
         
        
          e
          
            x
          
        
      
    
    }
  
 , мы положим 
  
    
      
        x
        =
        
          p
          
            i
          
        
        
      
    
    }
  
. Тот же результат можно получить, напрямую заменяя a в уравнении для оценки Чернова на  μ. 15 
Таким образом,
Если мы просто положим t = ln, так что t > 0 для δ > 0, то сможем подставить это в последнее выражение и найти
что и требовалось доказать.
